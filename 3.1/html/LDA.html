
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Section 3.1.2: Linear discriminant analysis (LDA)</title><meta name="generator" content="MATLAB 9.8"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2023-04-17"><meta name="DC.source" content="LDA.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Section 3.1.2: Linear discriminant analysis (LDA)</h1><!--introduction--><p>This page contains simulations in Section 3.1.2.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Basic settings</a></li><li><a href="#2">Empirical evaluation of LDA</a></li><li><a href="#3">Theoretical prediction of LDA decision (soft) output</a></li><li><a href="#4">FUNCTION</a></li></ul></div><h2 id="1">Basic settings</h2><pre class="codeinput">close <span class="string">all</span>; clear; clc

testcase = <span class="string">'Fashion-MNIST'</span>; <span class="comment">% Among 'GMM', 'MNIST', 'Fashion-MNIST', 'Kannada-MNIST', 'Kuzushiji-MNIST'</span>
<span class="keyword">switch</span> testcase
    <span class="keyword">case</span> <span class="string">'GMM'</span>
        testcase_option = <span class="string">'mixed'</span>; <span class="comment">% when testcase = 'GMM', among 'mean', 'cov', 'orth' and 'mixed'</span>
<span class="keyword">end</span>

coeff = 1;
n = 2048*coeff;
n_test = 128*coeff;
cs = [1/2 1/2];
k = length(cs);

<span class="keyword">switch</span> testcase
    <span class="keyword">case</span> <span class="string">'GMM'</span>
        p = 512*coeff;
        <span class="keyword">switch</span> testcase_option <span class="comment">% l = 0 or 1</span>
            <span class="keyword">case</span> <span class="string">'means'</span>
                means = @(l) [zeros(l+1,1);1;zeros(p-l-2,1)]*3;
                <span class="comment">%means = @(l) sqrt(2)*(-1)^l*[ones(p/2,1); -ones(p/2,1)]/sqrt(p);</span>
                covs  = @(l) eye(p);
            <span class="keyword">case</span> <span class="string">'cov'</span>
                means = @(l) zeros(p,1);
                covs  = @(l) eye(p)*(1+l/sqrt(p)*15);
            <span class="keyword">case</span> <span class="string">'orth'</span>
                means = @(l) zeros(p,1);
                covs = @(l) toeplitz((4*l/10).^(0:(p-1)));
            <span class="keyword">case</span> <span class="string">'mixed'</span>
                means = @(l) [zeros(l+1,1);1;zeros(p-l-2,1)]*3;
                covs = @(l) toeplitz((4*l/10).^(0:(p-1)));
                <span class="comment">%covs  = @(l) eye(p)*(1+l/sqrt(p)*20);</span>
                <span class="comment">%covs = @(l) toeplitz((4*l/10).^(0:(p-1)))*(1+l/sqrt(p)*4);</span>
        <span class="keyword">end</span>

    <span class="keyword">case</span> <span class="string">'MNIST'</span>
        init_data = loadMNISTImages(<span class="string">'../datasets/MNIST/train-images-idx3-ubyte'</span>);
        init_labels = loadMNISTLabels(<span class="string">'../datasets//MNIST/train-labels-idx1-ubyte'</span>);
    <span class="keyword">case</span> <span class="string">'Fashion-MNIST'</span>
        init_data = loadMNISTImages(<span class="string">'../datasets/Fashion-MNIST/train-images-idx3-ubyte'</span>);
        init_labels = loadMNISTLabels(<span class="string">'../datasets/Fashion-MNIST/train-labels-idx1-ubyte'</span>);
    <span class="keyword">case</span> <span class="string">'Kannada-MNIST'</span>
        init_data = loadMNISTImages(<span class="string">'../datasets/Kannada-MNIST/train-images-idx3-ubyte'</span>);
        init_labels = loadMNISTLabels(<span class="string">'../datasets/Kannada-MNIST/train-labels-idx1-ubyte'</span>);
    <span class="keyword">case</span> <span class="string">'Kuzushiji-MNIST'</span>
        init_data = loadMNISTImages(<span class="string">'../datasets/Kuzushiji-MNIST/train-images-idx3-ubyte'</span>);
        init_labels = loadMNISTLabels(<span class="string">'../datasets/Kuzushiji-MNIST/train-labels-idx1-ubyte'</span>);
<span class="keyword">end</span>

<span class="keyword">switch</span> testcase <span class="comment">% real-world data pre-processing</span>
    <span class="keyword">case</span> {<span class="string">'MNIST'</span>, <span class="string">'Fashion-MNIST'</span>,<span class="string">'Kannada-MNIST'</span>,<span class="string">'Kuzushiji-MNIST'</span>}
        [labels,idx_init_labels]=sort(init_labels,<span class="string">'ascend'</span>);
        data=init_data(:,idx_init_labels);

        init_n=length(data(1,:));
        p=length(data(:,1));

        selected_labels=[3 4];

        data = data/max(data(:));
        mean_data=mean(data,2);
        norm2_data=0;
        <span class="keyword">for</span> i=1:init_n
            norm2_data=norm2_data+1/init_n*norm(data(:,i)-mean_data)^2;
        <span class="keyword">end</span>
        data=(data-mean_data*ones(1,size(data,2)))/sqrt(norm2_data)*sqrt(p);

        selected_data = cell(k,1);
        cascade_selected_data=[];
        j=1;
        <span class="keyword">for</span> i=selected_labels
            selected_data{j}=data(:,labels==i);
            cascade_selected_data = [cascade_selected_data, selected_data{j}];
            j = j+1;
        <span class="keyword">end</span>

        <span class="comment">% recentering of the k classes</span>
        mean_selected_data=mean(cascade_selected_data,2);
        norm2_selected_data=mean(sum(abs(cascade_selected_data-mean_selected_data*ones(1,size(cascade_selected_data,2))).^2));

        <span class="keyword">for</span> j=1:length(selected_labels)
            selected_data{j}=(selected_data{j}-mean_selected_data*ones(1,size(selected_data{j},2)))/sqrt(norm2_selected_data)*sqrt(p);
        <span class="keyword">end</span>

        means = @(l) mean(selected_data{l+1},2);
        covs = @(l) 1/length(selected_data{l+1})*(selected_data{l+1}*selected_data{l+1}')-means(l)*means(l)';
<span class="keyword">end</span>
</pre><h2 id="2">Empirical evaluation of LDA</h2><pre class="codeinput">gamma = .1; <span class="comment">% regularization parameter</span>

nb_loop = 30;
T_store = zeros(n_test,nb_loop);
accuracy_store = zeros(nb_loop,1);
<span class="keyword">for</span> data_loop = 1:nb_loop

    <span class="keyword">switch</span> testcase <span class="comment">% generate data</span>
        <span class="keyword">case</span> {<span class="string">'MNIST'</span>, <span class="string">'Fashion-MNIST'</span>,<span class="string">'Kannada-MNIST'</span>,<span class="string">'Kuzushiji-MNIST'</span>}
            X=zeros(p,n);
            X_test=zeros(p,n_test);
            <span class="keyword">for</span> i=1:k <span class="comment">% random data picking</span>
                data = selected_data{i}(:,randperm(size(selected_data{i},2)));
                X(:,sum(cs(1:(i-1)))*n+1:sum(cs(1:i))*n)=data(:,1:n*cs(i));
                X_test(:,sum(cs(1:(i-1)))*n_test+1:sum(cs(1:i))*n_test)=data(:,n+1:n+n_test*cs(i));
            <span class="keyword">end</span>
        <span class="keyword">case</span> <span class="string">'GMM'</span>
            W=zeros(p,n);
            W_test=zeros(p,n_test);
            <span class="keyword">for</span> i=1:k
                W(:,sum(cs(1:(i-1)))*n+1:sum(cs(1:i))*n)=sqrtm(covs(i-1))*randn(p,cs(i)*n);
                W_test(:,sum(cs(1:(i-1)))*n_test+1:sum(cs(1:i))*n_test)=sqrtm(covs(i-1))*randn(p,cs(i)*n_test);
            <span class="keyword">end</span>

            X=zeros(p,n);
            X_test=zeros(p,n_test);
            <span class="keyword">for</span> i=1:k
                X(:,sum(cs(1:(i-1)))*n+1:sum(cs(1:i))*n)=W(:,sum(cs(1:(i-1)))*n+1:sum(cs(1:i))*n)+means(i-1)*ones(1,cs(i)*n);
                X_test(:,sum(cs(1:(i-1)))*n_test+1:sum(cs(1:i))*n_test)=W_test(:,sum(cs(1:(i-1)))*n_test+1:sum(cs(1:i))*n_test)+means(i-1)*ones(1,cs(i)*n_test);
            <span class="keyword">end</span>
    <span class="keyword">end</span>

    <span class="comment">% run LDA</span>
    X_train0 = X(:,1:n*cs(1));
    X_train1 = X(:,n*cs(1)+1:end);

    hat_mu0 = X_train0*ones(n*cs(1),1)/(n*cs(1));
    hat_mu1 = X_train1*ones(n*cs(2),1)/(n*cs(2));
    hat_mu = (hat_mu0 + hat_mu1)/2;

    P = @(l) eye(cs(l+1)*n) - ones(cs(l+1)*n, cs(l+1)*n)/(cs(l+1)*n);
    hat_C_gamma = ( X_train0*P(0)*(X_train0') + X_train1*P(1)*(X_train1') )/(n-2) + gamma*eye(p);

    <span class="comment">% decision function</span>
    T = @(x) (x - hat_mu)'*( hat_C_gamma\(hat_mu0 - hat_mu1) );
    T_store(:,data_loop) = T(X_test);

    accuracy_store(data_loop) = sum(T(X_test(:,1:cs(1)*n_test))&gt;0)/(n_test*cs(1))/2+sum(T(X_test(:,cs(1)*n_test+1:end))&lt;0)/(n_test*cs(2))/2;
<span class="keyword">end</span>

T_store0 = T_store(1:cs(1)*n_test,:);
T_store1 = T_store(cs(1)*n_test+1:end,:);

disp([<span class="string">'Classif accuracy:'</span>, num2str(mean(accuracy_store))]);
</pre><pre class="codeoutput">Classif accuracy:0.94818
</pre><h2 id="3">Theoretical prediction of LDA decision (soft) output</h2><pre class="codeinput">eigs_C = @(l) eig(covs(l));

z = - gamma;
tilde_g = ones(2,1);
tilde_g_tmp = zeros(2,1);
g = zeros(2,1);

<span class="comment">%watch_dog = 1;</span>
<span class="keyword">while</span> min(abs(tilde_g-tilde_g_tmp))&gt;1e-6 <span class="comment">%%&amp;&amp; watch_dog&lt;50</span>
    tilde_g_tmp = tilde_g;

    eigs_C_sum = cs(1)*tilde_g(1)*eigs_C(0) + cs(2)*tilde_g(2)*eigs_C(1);

    <span class="keyword">for</span> a = 1:2
        g(a) = -1/z*sum( eigs_C(a-1)./(1 + eigs_C_sum) )/n;
        tilde_g(a) = -1/z/(1+g(a));
    <span class="keyword">end</span>

<span class="keyword">end</span>
bar_Q = -1/z*inv( eye(p) + cs(1)*tilde_g(1)*covs(0) + cs(2)*tilde_g(2)*covs(1) );

S = gamma^2*[cs(1)*tilde_g(1)^2*trace( covs(0)*bar_Q*covs(0)*bar_Q )/n, cs(2)*tilde_g(1)^2*trace( covs(0)*bar_Q*covs(1)*bar_Q )/n; cs(1)*tilde_g(2)^2*trace( covs(0)*bar_Q*covs(1)*bar_Q )/n, cs(2)*tilde_g(2)^2*trace( covs(1)*bar_Q*covs(1)*bar_Q )/n];
tmp_S = (eye(2) - S)\S;
R = @(ll,l) cs(ll+1)/cs(l+1)*tmp_S(ll+1,l+1);

bar_QCQ = @(l) bar_Q*covs(l)*bar_Q + R(0,l)*bar_Q*covs(0)*bar_Q + R(1,l)*bar_Q*covs(1)*bar_Q;

delta_mu = means(0) - means(1);
theo_mean = @(l) (-1)^l*delta_mu'*bar_Q*delta_mu/2 - g(1)/2/cs(1) + g(2)/2/cs(2);
theo_var = @(l) delta_mu'*bar_QCQ(l)*delta_mu + trace(covs(0)*bar_QCQ(l))/(n*cs(1)) + trace(covs(1)*bar_QCQ(l))/(n*cs(2));

edges = linspace(min([T_store0(:);T_store1(:)])-.5,max([T_store0(:);T_store1(:)])+.5,300);

figure
hold <span class="string">on</span>
histogram(T_store0(:),30,<span class="string">'Normalization'</span>,<span class="string">'pdf'</span>,<span class="string">'EdgeColor'</span>, <span class="string">'white'</span>);
histogram(T_store1(:),30,<span class="string">'Normalization'</span>,<span class="string">'pdf'</span>,<span class="string">'EdgeColor'</span>, <span class="string">'white'</span>);
plot(edges,normpdf(edges, theo_mean(0), sqrt(theo_var(0))),<span class="string">'--b'</span>);
plot(edges,normpdf(edges, theo_mean(1), sqrt(theo_var(1))),<span class="string">'--r'</span>);
legend(<span class="string">'Empirical $T(x\sim \mathcal H_0)$'</span>, <span class="string">'Empirical $T(x\sim \mathcal H_1)$'</span>, <span class="string">'Theory $T(x\sim \mathcal H_0)$'</span>, <span class="string">'Theory $T(x\sim \mathcal H_1)$'</span>, <span class="string">'Interpreter'</span>,<span class="string">'latex'</span>, <span class="string">'FontSize'</span>, 15)
</pre><img vspace="5" hspace="5" src="LDA_01.png" alt=""> <h2 id="4">FUNCTION</h2><pre class="codeinput"><span class="keyword">function</span> images = loadMNISTImages(filename)
<span class="comment">%loadMNISTImages returns a 28x28x[number of MNIST images] matrix containing</span>
<span class="comment">%the raw MNIST images</span>
<span class="comment">%from</span>

fp = fopen(filename, <span class="string">'rb'</span>);
assert(fp ~= -1, [<span class="string">'Could not open '</span>, filename, <span class="string">''</span>]);

magic = fread(fp, 1, <span class="string">'int32'</span>, 0, <span class="string">'ieee-be'</span>);
assert(magic == 2051, [<span class="string">'Bad magic number in '</span>, filename, <span class="string">''</span>]);

numImages = fread(fp, 1, <span class="string">'int32'</span>, 0, <span class="string">'ieee-be'</span>);
numRows = fread(fp, 1, <span class="string">'int32'</span>, 0, <span class="string">'ieee-be'</span>);
numCols = fread(fp, 1, <span class="string">'int32'</span>, 0, <span class="string">'ieee-be'</span>);

images = fread(fp, inf, <span class="string">'unsigned char'</span>);
images = reshape(images, numCols, numRows, numImages);
images = permute(images,[2 1 3]);

fclose(fp);

<span class="comment">% Reshape to #pixels x #examples</span>
images = reshape(images, size(images, 1) * size(images, 2), size(images, 3));
<span class="comment">% Convert to double and rescale to [0,1]</span>
images = double(images) / 255;

<span class="keyword">end</span>

<span class="keyword">function</span> labels = loadMNISTLabels(filename)
<span class="comment">%loadMNISTLabels returns a [number of MNIST images]x1 matrix containing</span>
<span class="comment">%the labels for the MNIST images</span>

fp = fopen(filename, <span class="string">'rb'</span>);
assert(fp ~= -1, [<span class="string">'Could not open '</span>, filename, <span class="string">''</span>]);

magic = fread(fp, 1, <span class="string">'int32'</span>, 0, <span class="string">'ieee-be'</span>);
assert(magic == 2049, [<span class="string">'Bad magic number in '</span>, filename, <span class="string">''</span>]);

numLabels = fread(fp, 1, <span class="string">'int32'</span>, 0, <span class="string">'ieee-be'</span>);

labels = fread(fp, inf, <span class="string">'unsigned char'</span>);

assert(size(labels,1) == numLabels, <span class="string">'Mismatch in label count'</span>);

fclose(fp);

<span class="keyword">end</span>
</pre><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2020a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Section 3.1.2: Linear discriminant analysis (LDA)
% This page contains simulations in Section 3.1.2.

%% Basic settings
close all; clear; clc

testcase = 'Fashion-MNIST'; % Among 'GMM', 'MNIST', 'Fashion-MNIST', 'Kannada-MNIST', 'Kuzushiji-MNIST'
switch testcase
    case 'GMM'
        testcase_option = 'mixed'; % when testcase = 'GMM', among 'mean', 'cov', 'orth' and 'mixed'
end

coeff = 1;
n = 2048*coeff;
n_test = 128*coeff;
cs = [1/2 1/2]; 
k = length(cs);

switch testcase
    case 'GMM'
        p = 512*coeff; 
        switch testcase_option % l = 0 or 1
            case 'means'
                means = @(l) [zeros(l+1,1);1;zeros(p-l-2,1)]*3;
                %means = @(l) sqrt(2)*(-1)^l*[ones(p/2,1); -ones(p/2,1)]/sqrt(p);
                covs  = @(l) eye(p);
            case 'cov'
                means = @(l) zeros(p,1);
                covs  = @(l) eye(p)*(1+l/sqrt(p)*15);
            case 'orth'
                means = @(l) zeros(p,1);
                covs = @(l) toeplitz((4*l/10).^(0:(p-1)));
            case 'mixed'
                means = @(l) [zeros(l+1,1);1;zeros(p-l-2,1)]*3;
                covs = @(l) toeplitz((4*l/10).^(0:(p-1)));
                %covs  = @(l) eye(p)*(1+l/sqrt(p)*20);
                %covs = @(l) toeplitz((4*l/10).^(0:(p-1)))*(1+l/sqrt(p)*4);
        end
        
    case 'MNIST'
        init_data = loadMNISTImages('../datasets/MNIST/train-images-idx3-ubyte');
        init_labels = loadMNISTLabels('../datasets//MNIST/train-labels-idx1-ubyte');
    case 'Fashion-MNIST'
        init_data = loadMNISTImages('../datasets/Fashion-MNIST/train-images-idx3-ubyte');
        init_labels = loadMNISTLabels('../datasets/Fashion-MNIST/train-labels-idx1-ubyte');
    case 'Kannada-MNIST'
        init_data = loadMNISTImages('../datasets/Kannada-MNIST/train-images-idx3-ubyte');
        init_labels = loadMNISTLabels('../datasets/Kannada-MNIST/train-labels-idx1-ubyte');
    case 'Kuzushiji-MNIST'
        init_data = loadMNISTImages('../datasets/Kuzushiji-MNIST/train-images-idx3-ubyte');
        init_labels = loadMNISTLabels('../datasets/Kuzushiji-MNIST/train-labels-idx1-ubyte');
end

switch testcase % real-world data pre-processing 
    case {'MNIST', 'Fashion-MNIST','Kannada-MNIST','Kuzushiji-MNIST'}
        [labels,idx_init_labels]=sort(init_labels,'ascend');
        data=init_data(:,idx_init_labels);
        
        init_n=length(data(1,:));
        p=length(data(:,1));
        
        selected_labels=[3 4];   
        
        data = data/max(data(:));
        mean_data=mean(data,2);
        norm2_data=0;
        for i=1:init_n
            norm2_data=norm2_data+1/init_n*norm(data(:,i)-mean_data)^2;
        end
        data=(data-mean_data*ones(1,size(data,2)))/sqrt(norm2_data)*sqrt(p);
        
        selected_data = cell(k,1);
        cascade_selected_data=[];
        j=1;
        for i=selected_labels
            selected_data{j}=data(:,labels==i);
            cascade_selected_data = [cascade_selected_data, selected_data{j}];
            j = j+1;
        end
        
        % recentering of the k classes
        mean_selected_data=mean(cascade_selected_data,2);
        norm2_selected_data=mean(sum(abs(cascade_selected_data-mean_selected_data*ones(1,size(cascade_selected_data,2))).^2));
        
        for j=1:length(selected_labels)
            selected_data{j}=(selected_data{j}-mean_selected_data*ones(1,size(selected_data{j},2)))/sqrt(norm2_selected_data)*sqrt(p);
        end
        
        means = @(l) mean(selected_data{l+1},2);
        covs = @(l) 1/length(selected_data{l+1})*(selected_data{l+1}*selected_data{l+1}')-means(l)*means(l)';
end

%% Empirical evaluation of LDA
gamma = .1; % regularization parameter

nb_loop = 30;
T_store = zeros(n_test,nb_loop);
accuracy_store = zeros(nb_loop,1);
for data_loop = 1:nb_loop
    
    switch testcase % generate data
        case {'MNIST', 'Fashion-MNIST','Kannada-MNIST','Kuzushiji-MNIST'}
            X=zeros(p,n);
            X_test=zeros(p,n_test);
            for i=1:k % random data picking
                data = selected_data{i}(:,randperm(size(selected_data{i},2)));
                X(:,sum(cs(1:(i-1)))*n+1:sum(cs(1:i))*n)=data(:,1:n*cs(i));
                X_test(:,sum(cs(1:(i-1)))*n_test+1:sum(cs(1:i))*n_test)=data(:,n+1:n+n_test*cs(i));
            end
        case 'GMM'
            W=zeros(p,n);
            W_test=zeros(p,n_test);
            for i=1:k
                W(:,sum(cs(1:(i-1)))*n+1:sum(cs(1:i))*n)=sqrtm(covs(i-1))*randn(p,cs(i)*n);
                W_test(:,sum(cs(1:(i-1)))*n_test+1:sum(cs(1:i))*n_test)=sqrtm(covs(i-1))*randn(p,cs(i)*n_test);
            end
            
            X=zeros(p,n);
            X_test=zeros(p,n_test);
            for i=1:k
                X(:,sum(cs(1:(i-1)))*n+1:sum(cs(1:i))*n)=W(:,sum(cs(1:(i-1)))*n+1:sum(cs(1:i))*n)+means(i-1)*ones(1,cs(i)*n);
                X_test(:,sum(cs(1:(i-1)))*n_test+1:sum(cs(1:i))*n_test)=W_test(:,sum(cs(1:(i-1)))*n_test+1:sum(cs(1:i))*n_test)+means(i-1)*ones(1,cs(i)*n_test);
            end
    end
    
    % run LDA
    X_train0 = X(:,1:n*cs(1));
    X_train1 = X(:,n*cs(1)+1:end);
    
    hat_mu0 = X_train0*ones(n*cs(1),1)/(n*cs(1));
    hat_mu1 = X_train1*ones(n*cs(2),1)/(n*cs(2));
    hat_mu = (hat_mu0 + hat_mu1)/2;
    
    P = @(l) eye(cs(l+1)*n) - ones(cs(l+1)*n, cs(l+1)*n)/(cs(l+1)*n);
    hat_C_gamma = ( X_train0*P(0)*(X_train0') + X_train1*P(1)*(X_train1') )/(n-2) + gamma*eye(p);
    
    % decision function
    T = @(x) (x - hat_mu)'*( hat_C_gamma\(hat_mu0 - hat_mu1) );
    T_store(:,data_loop) = T(X_test); 
    
    accuracy_store(data_loop) = sum(T(X_test(:,1:cs(1)*n_test))>0)/(n_test*cs(1))/2+sum(T(X_test(:,cs(1)*n_test+1:end))<0)/(n_test*cs(2))/2;
end

T_store0 = T_store(1:cs(1)*n_test,:);
T_store1 = T_store(cs(1)*n_test+1:end,:);

disp(['Classif accuracy:', num2str(mean(accuracy_store))]);

%% Theoretical prediction of LDA decision (soft) output
eigs_C = @(l) eig(covs(l));

z = - gamma;
tilde_g = ones(2,1);
tilde_g_tmp = zeros(2,1);
g = zeros(2,1);

%watch_dog = 1;
while min(abs(tilde_g-tilde_g_tmp))>1e-6 %%&& watch_dog<50
    tilde_g_tmp = tilde_g;
    
    eigs_C_sum = cs(1)*tilde_g(1)*eigs_C(0) + cs(2)*tilde_g(2)*eigs_C(1);
    
    for a = 1:2
        g(a) = -1/z*sum( eigs_C(a-1)./(1 + eigs_C_sum) )/n;
        tilde_g(a) = -1/z/(1+g(a));
    end
    
end
bar_Q = -1/z*inv( eye(p) + cs(1)*tilde_g(1)*covs(0) + cs(2)*tilde_g(2)*covs(1) );

S = gamma^2*[cs(1)*tilde_g(1)^2*trace( covs(0)*bar_Q*covs(0)*bar_Q )/n, cs(2)*tilde_g(1)^2*trace( covs(0)*bar_Q*covs(1)*bar_Q )/n; cs(1)*tilde_g(2)^2*trace( covs(0)*bar_Q*covs(1)*bar_Q )/n, cs(2)*tilde_g(2)^2*trace( covs(1)*bar_Q*covs(1)*bar_Q )/n];
tmp_S = (eye(2) - S)\S;
R = @(ll,l) cs(ll+1)/cs(l+1)*tmp_S(ll+1,l+1);

bar_QCQ = @(l) bar_Q*covs(l)*bar_Q + R(0,l)*bar_Q*covs(0)*bar_Q + R(1,l)*bar_Q*covs(1)*bar_Q;

delta_mu = means(0) - means(1);
theo_mean = @(l) (-1)^l*delta_mu'*bar_Q*delta_mu/2 - g(1)/2/cs(1) + g(2)/2/cs(2);
theo_var = @(l) delta_mu'*bar_QCQ(l)*delta_mu + trace(covs(0)*bar_QCQ(l))/(n*cs(1)) + trace(covs(1)*bar_QCQ(l))/(n*cs(2));

edges = linspace(min([T_store0(:);T_store1(:)])-.5,max([T_store0(:);T_store1(:)])+.5,300);

figure
hold on
histogram(T_store0(:),30,'Normalization','pdf','EdgeColor', 'white');
histogram(T_store1(:),30,'Normalization','pdf','EdgeColor', 'white');
plot(edges,normpdf(edges, theo_mean(0), sqrt(theo_var(0))),'REPLACE_WITH_DASH_DASHb');
plot(edges,normpdf(edges, theo_mean(1), sqrt(theo_var(1))),'REPLACE_WITH_DASH_DASHr');
legend('Empirical $T(x\sim \mathcal H_0)$', 'Empirical $T(x\sim \mathcal H_1)$', 'Theory $T(x\sim \mathcal H_0)$', 'Theory $T(x\sim \mathcal H_1)$', 'Interpreter','latex', 'FontSize', 15)


%% FUNCTION
function images = loadMNISTImages(filename)
%loadMNISTImages returns a 28x28x[number of MNIST images] matrix containing
%the raw MNIST images
%from 

fp = fopen(filename, 'rb');
assert(fp ~= -1, ['Could not open ', filename, '']);

magic = fread(fp, 1, 'int32', 0, 'ieee-be');
assert(magic == 2051, ['Bad magic number in ', filename, '']);

numImages = fread(fp, 1, 'int32', 0, 'ieee-be');
numRows = fread(fp, 1, 'int32', 0, 'ieee-be');
numCols = fread(fp, 1, 'int32', 0, 'ieee-be');

images = fread(fp, inf, 'unsigned char');
images = reshape(images, numCols, numRows, numImages);
images = permute(images,[2 1 3]);

fclose(fp);

% Reshape to #pixels x #examples
images = reshape(images, size(images, 1) * size(images, 2), size(images, 3));
% Convert to double and rescale to [0,1]
images = double(images) / 255;

end

function labels = loadMNISTLabels(filename)
%loadMNISTLabels returns a [number of MNIST images]x1 matrix containing
%the labels for the MNIST images

fp = fopen(filename, 'rb');
assert(fp ~= -1, ['Could not open ', filename, '']);

magic = fread(fp, 1, 'int32', 0, 'ieee-be');
assert(magic == 2049, ['Bad magic number in ', filename, '']);

numLabels = fread(fp, 1, 'int32', 0, 'ieee-be');

labels = fread(fp, inf, 'unsigned char');

assert(size(labels,1) == numLabels, 'Mismatch in label count');

fclose(fp);

end

##### SOURCE END #####
--></body></html>